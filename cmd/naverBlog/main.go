package main

import (
	"crypto/tls"
	"fmt"
	"log"
	"naverCafeCrawler/internal/crawling"
	"naverCafeCrawler/internal/utils"
	"net/http"
	"os"
	"path/filepath"
	"sync"
	"time"

	"github.com/joho/godotenv"
)

// HTTP í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì¬ì‚¬ìš©)
var client = &http.Client{
	Transport: &http.Transport{
		TLSClientConfig: &tls.Config{
			MinVersion: tls.VersionTLS12,
		},
	},
	Timeout: 30 * time.Second, // íƒ€ì„ì•„ì›ƒ ì¦ê°€
}

func init() {
	log.SetFlags(log.LstdFlags | log.Lmicroseconds)
}

// ë¸”ë¡œê·¸ í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „
func CrawlBlog(blogID string, maxPages int) ([]crawling.BlogPost, error) {
	log.Printf("ğŸš€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ '%s' í¬ë¡¤ë§ ì‹œì‘...", blogID)

	var allPosts []crawling.BlogPost
	var mu sync.Mutex

	outputDir := "output_blog"
	aiReadyDir := filepath.Join(outputDir, "ai_ready")

	// ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
	if err := os.MkdirAll(outputDir, 0755); err != nil {
		return nil, fmt.Errorf("ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: %v", err)
	}
	if err := os.MkdirAll(aiReadyDir, 0755); err != nil {
		return nil, fmt.Errorf("AI Ready ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: %v", err)
	}

	// ìˆœì°¨ ì²˜ë¦¬ë¡œ ë³€ê²½ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” ë™ì‹œ ìš”ì²­ì— ë¯¼ê°í•  ìˆ˜ ìˆìŒ)
	for page := 1; page <= maxPages; page++ {
		log.Printf("ğŸ”„ %d/%d í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...", page, maxPages)

		postsOnPage, err := crawling.GetBlogPostList(blogID, page)
		if err != nil {
			log.Printf("âš ï¸ í˜ì´ì§€ %d ê²Œì‹œê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: %v", page, err)
			continue // ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ í˜ì´ì§€ ì§„í–‰
		}

		if len(postsOnPage) == 0 {
			log.Printf("âš ï¸ í˜ì´ì§€ %dì—ì„œ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", page)
			continue
		}

		var detailedPostsOnPage []crawling.BlogPost
		for i, post := range postsOnPage {
			log.Printf("  ğŸ“– %dí˜ì´ì§€ ê²Œì‹œê¸€ %d/%d ìƒì„¸ ì •ë³´ ì²˜ë¦¬ ì¤‘... (ID: %s)", page, i+1, len(postsOnPage), post.ID)

			detail, err := crawling.GetBlogPostDetail(blogID, post.ID)
			if err != nil {
				log.Printf("âš ï¸ ê²Œì‹œê¸€ %s ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: %v", post.ID, err)
				continue
			}

			// ë¹ˆ ê²Œì‹œê¸€ì€ ì œì™¸
			if detail.Title != "" || detail.Content != "" {
				detailedPostsOnPage = append(detailedPostsOnPage, detail)
			}
		}

		if len(detailedPostsOnPage) == 0 {
			log.Printf("âš ï¸ í˜ì´ì§€ %dì—ì„œ ìœ íš¨í•œ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", page)
			continue
		}

		mu.Lock()
		allPosts = append(allPosts, detailedPostsOnPage...)
		mu.Unlock()

		// í˜ì´ì§€ë³„ ì €ì¥
		timestamp := time.Now().Format("20060102_150405")
		pageFilename := filepath.Join(outputDir, fmt.Sprintf("blog_%s_page_%d_%s.json", blogID, page, timestamp))

		if err := utils.SaveToJSON(detailedPostsOnPage, pageFilename); err != nil {
			log.Printf("âš ï¸ %dí˜ì´ì§€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", page, err)
		}

		// AI Ready í˜•ì‹ìœ¼ë¡œ ì €ì¥
		var aiReadyPosts []map[string]interface{}
		for _, post := range detailedPostsOnPage {
			aiReadyPost := map[string]interface{}{
				"title":   post.Title,
				"content": post.Content,
				"metadata": map[string]interface{}{
					"id":         post.ID,
					"writer":     post.Writer,
					"write_date": post.WriteDate,
					"url":        post.OriginalURL,
				},
				"comments": post.Comments,
			}
			aiReadyPosts = append(aiReadyPosts, aiReadyPost)
		}

		aiReadyFilename := filepath.Join(aiReadyDir, fmt.Sprintf("blog_%s_page_%d_%s_ai_ready.json", blogID, page, timestamp))
		if err := utils.SaveToJSON(aiReadyPosts, aiReadyFilename); err != nil {
			log.Printf("âš ï¸ %dí˜ì´ì§€ AI Ready ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", page, err)
		}

		log.Printf("âœ… %d/%d í˜ì´ì§€ í¬ë¡¤ë§ ì™„ë£Œ (ìˆ˜ì§‘ ê²Œì‹œê¸€ %dê°œ)", page, maxPages, len(detailedPostsOnPage))
	}

	// ì „ì²´ ê²°ê³¼ ì €ì¥
	if len(allPosts) > 0 {
		timestamp := time.Now().Format("20060102_150405")
		fullFilename := filepath.Join(outputDir, fmt.Sprintf("blog_%s_full_%s.json", blogID, timestamp))

		if err := utils.SaveToJSON(allPosts, fullFilename); err != nil {
			log.Printf("âš ï¸ ì „ì²´ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", err)
		}

		// AI Ready ì „ì²´ ê²°ê³¼ ì €ì¥
		var allAiReadyPosts []map[string]interface{}
		for _, post := range allPosts {
			aiReadyPost := map[string]interface{}{
				"title":   post.Title,
				"content": post.Content,
				"metadata": map[string]interface{}{
					"id":         post.ID,
					"writer":     post.Writer,
					"write_date": post.WriteDate,
					"url":        post.OriginalURL,
				},
				"comments": post.Comments,
			}
			allAiReadyPosts = append(allAiReadyPosts, aiReadyPost)
		}

		aiReadyFullFilename := filepath.Join(aiReadyDir, fmt.Sprintf("blog_%s_full_%s_ai_ready.json", blogID, timestamp))
		if err := utils.SaveToJSON(allAiReadyPosts, aiReadyFullFilename); err != nil {
			log.Printf("âš ï¸ AI Ready ì „ì²´ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", err)
		}
	}

	log.Printf("ğŸ‰ ë„¤ì´ë²„ ë¸”ë¡œê·¸ '%s' í¬ë¡¤ë§ ì™„ë£Œ! ì´ %dê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘", blogID, len(allPosts))
	return allPosts, nil
}

func main() {
	err := godotenv.Load()
	if err != nil && !os.IsNotExist(err) {
		fmt.Println("Error loading .env file:", err)
		return
	}

	blogID := os.Getenv("NAVER_BLOG_ID")
	if blogID == "" {
		log.Fatal("NAVER_BLOG_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
	}

	maxPages := 3

	log.Printf("ğŸ¯ ëŒ€ìƒ ë¸”ë¡œê·¸: %s", blogID)
	log.Printf("ğŸ“„ í¬ë¡¤ë§ í˜ì´ì§€ ìˆ˜: %d", maxPages)

	posts, err := CrawlBlog(blogID, maxPages)
	if err != nil {
		log.Fatal("âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", err)
	}

	fmt.Printf("âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ %dê°œ ë¸”ë¡œê·¸ ê²Œì‹œê¸€ ìˆ˜ì§‘\n", len(posts))

	// ê²°ê³¼ ìš”ì•½ ì¶œë ¥
	if len(posts) > 0 {
		fmt.Printf("\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\n")
		for i, post := range posts {
			if i >= 5 { // ìµœëŒ€ 5ê°œë§Œ ì¶œë ¥
				fmt.Printf("... ì™¸ %dê°œ ê²Œì‹œê¸€\n", len(posts)-5)
				break
			}
			fmt.Printf("ğŸ“Œ [%d] %s\n", i+1, post.Title)
			fmt.Printf("   ğŸ‘¤ %s | ğŸ“… %s | ğŸ’¬ %dê°œ ëŒ“ê¸€\n", post.Writer, post.WriteDate, len(post.Comments))
			fmt.Printf("   ğŸ“ %s...\n", utils.TruncateString(post.Content, 100))
			fmt.Println()
		}
	} else {
		fmt.Println("âš ï¸ ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤. ë¸”ë¡œê·¸ IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
	}
}
